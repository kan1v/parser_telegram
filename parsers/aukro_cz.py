from playwright.async_api import async_playwright, Page
import asyncio
import logging
import os
import urllib.parse

from utils import get_random_user_agent, load_seen_links, save_seen_links, get_rotated_proxy

LOG_DIR = "logs"
os.makedirs(LOG_DIR, exist_ok=True)
SEEN_FILE = "parsers/aukro_cz_seen.json"

logger = logging.getLogger("aukro")
logger.setLevel(logging.INFO)

if not logger.hasHandlers():
    fh = logging.FileHandler(os.path.join(LOG_DIR, "aukro.log"), encoding="utf-8")
    fh.setFormatter(logging.Formatter("%(asctime)s | %(levelname)s | %(message)s"))
    logger.addHandler(fh)
    logger.addHandler(logging.StreamHandler())

CARD_SELECTORS = [
    "a.item-card-main-container",
    "a.tw-group.item-card.tw-min-w-\\[16\\.5rem\\]",
    "a.item-card",
]


async def popup_watcher(page: Page, run_flag: asyncio.Event):
    selector = "a:has(i.material-icons.cursor-pointer.vertical-bottom)"
    logger.info("üëÅ –ü–æ–ø–∞–ø-—Å—Ç—Ä–∞–∂ –∑–∞–ø—É—â–µ–Ω")

    while not run_flag.is_set():
        try:
            popup = await page.query_selector(selector)
            if popup:
                await popup.click()
                logger.info(f"‚úÖ –ü–æ–ø–∞–ø –∑–∞–∫—Ä—ã—Ç: {selector}")
                await asyncio.sleep(1.0)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ –ø–æ–ø–∞–ø–∞: {e}")
        await asyncio.sleep(1.5)

    logger.info("üëÅ –ü–æ–ø–∞–ø-—Å—Ç—Ä–∞–∂ –∑–∞–≤–µ—Ä—à—ë–Ω")


async def auto_scroll(page: Page):
    last_count = 0
    attempts = 0
    max_scrolls = 30

    for i in range(max_scrolls):
        logger.info(f"üîÄ –°–∫—Ä–æ–ª–ª {i + 1}/{max_scrolls}")
        await page.mouse.wheel(0, 1200)
        await asyncio.sleep(2.5)

        found = []
        for sel in CARD_SELECTORS:
            items = await page.query_selector_all(sel)
            if items:
                logger.info(f"‚úÖ –°–µ–ª–µ–∫—Ç–æ—Ä —Å—Ä–∞–±–æ—Ç–∞–ª: {sel} ‚Äî –Ω–∞–π–¥–µ–Ω–æ {len(items)} –∫–∞—Ä—Ç–æ—á–µ–∫")
                found = items
                break
            else:
                logger.debug(f"‚ùå –°–µ–ª–µ–∫—Ç–æ—Ä {sel} –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

        count = len(found)
        if count > last_count:
            last_count = count
            attempts = 0
        else:
            attempts += 1

        if attempts >= 3:
            logger.info("üö© 3 —Å–∫—Ä–æ–ª–ª–∞ –ø–æ–¥—Ä—è–¥ –±–µ–∑ –Ω–æ–≤—ã—Ö –∫–∞—Ä—Ç–æ—á–µ–∫.")
            break

    await asyncio.sleep(2.0)
    return found


async def search_aukro(keyword: str):
    encoded_keyword = urllib.parse.quote(keyword)
    url = f"https://aukro.cz/vysledky-vyhledavani?text={encoded_keyword}&categoryId=8466"
    logger.info(f"üîé –û—Ç–∫—Ä—ã–≤–∞–µ–º Aukro: {url}")
    found_links = []

    seen_links_raw = load_seen_links(SEEN_FILE)
    seen_links = set(link.strip().lower() for link in seen_links_raw)

    async with async_playwright() as p:
        user_agent = get_random_user_agent()
        proxy = get_rotated_proxy(keyword)
        logger.info(f"üåê –ü—Ä–æ–∫—Å–∏: {proxy['server']}")

        launch_args = {"headless": True}
        if proxy:
            launch_args["proxy"] = {
                "server": proxy["server"],
                "username": proxy.get("username"),
                "password": proxy.get("password"),
            }

        browser = await p.chromium.launch(**launch_args)
        context = await browser.new_context(user_agent=user_agent)
        page = await context.new_page()

        try:
            await page.goto(url, wait_until="domcontentloaded", timeout=50000)
            await asyncio.sleep(3.0)

            stop_flag = asyncio.Event()
            watcher_task = asyncio.create_task(popup_watcher(page, stop_flag))

            # ‚¨áÔ∏è –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π —Å–∫—Ä–æ–ª–ª–∏–Ω–≥ —Å –ø–æ–ø—ã—Ç–∫–∞–º–∏
            elements = await auto_scroll(page)

            stop_flag.set()
            await watcher_task

            if not elements:
                logger.warning("üì≠ –ö–∞—Ä—Ç–æ—á–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –ø–æ—Å–ª–µ —Å–∫—Ä–æ–ª–ª–∏–Ω–≥–∞.")
                return []

            top_links = []
            for el in elements:
                if len(top_links) >= 15:
                    break

                href = await el.get_attribute("href")
                if href and href.startswith("/"):
                    full_url = f"https://aukro.cz{href.strip()}"
                    normalized = full_url.strip().lower()
                    top_links.append(normalized)

            new_links = [link for link in top_links if link not in seen_links]

            if new_links:
                found_links = new_links
                seen_links.update(top_links)
                save_seen_links(SEEN_FILE, seen_links)
                logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –Ω–æ–≤—ã—Ö —Å—Å—ã–ª–æ–∫: {len(new_links)}")
            else:
                logger.info("üì≠ –í—Å–µ 15 —Å—Å—ã–ª–æ–∫ —É–∂–µ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω—ã. –ù–æ–≤—ã—Ö –Ω–µ—Ç.")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ Aukro: {e}")
        finally:
            await browser.close()

    if found_links:
        logger.info(f"üß† –ü–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–æ–≤—ã–µ: {found_links[-3:]}")
    return found_links
