import asyncio
import logging
import os
import random

from utils import (
    load_keywords,
    load_seen_links,
    save_seen_links,
    normalize_link,
)
from config import KEYWORDS_FILE, SEEN_LINKS_FILE
from parsers.bazos_cz import search_bazos
from parsers.vinted_cz import search_vinted
from parsers.sbazar_cz import search_sbazar
from parsers.aukro_cz import search_aukro
from telegram_bot import send_to_telegram, run_bot, stop_parsing

# üëá –°–µ–º–∞—Ñ–æ—Ä—ã –ø–æ —Å–∞–π—Ç–∞–º
SEMAPHORES = {
    "aukro": asyncio.Semaphore(7),
    "bazos": asyncio.Semaphore(5),
    "sbazar": asyncio.Semaphore(7),
    "vinted": asyncio.Semaphore(7),
}

LOG_DIR = "logs"
os.makedirs(LOG_DIR, exist_ok=True)

logger = logging.getLogger("main")
logger.setLevel(logging.INFO)

if not logger.hasHandlers():
    fh = logging.FileHandler(os.path.join(LOG_DIR, "main.log"), encoding="utf-8")
    fh.setFormatter(logging.Formatter("%(asctime)s | %(levelname)s | %(message)s"))
    logger.addHandler(fh)
    logger.addHandler(logging.StreamHandler())

# –•—Ä–∞–Ω–∏–ª–∏—â–µ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã—Ö —Å—Å—ã–ª–æ–∫
seen_links_store: dict[str, set[str]] = {}

# –ö–∞—Ä—Ç–∞ –ø–∞—Ä—Å–µ—Ä–æ–≤
PARSERS = {
    "bazos": search_bazos,
    "vinted": search_vinted,
    "sbazar": search_sbazar,
    "aukro": search_aukro,
}


async def send_links_separately(links: list[str], site: str, keyword: str):
    for link in links:
        message = f"üîç <b>{site.upper()}</b> | <b>{keyword}</b>\n{link}"
        try:
            await send_to_telegram(message)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram: {e}")


async def process_keyword(site: str, keyword: str, func, sema: asyncio.Semaphore):
    try:
        if stop_parsing:
            logger.warning(f"[{site}] –ü—Ä–æ–ø—É—â–µ–Ω –∫–ª—é—á '{keyword}' –∏–∑-–∑–∞ –∑–∞–º–µ–Ω—ã keywords.txt")
            return

        async with sema:
            await asyncio.sleep(random.uniform(1.2, 2.8))  # ‚è±Ô∏è –∞–Ω—Ç–∏—Å–ø–∞–º-–∑–∞–¥–µ—Ä–∂–∫–∞

            seen_links = seen_links_store.get(site, set())
            links = await func(keyword)
            normalized_links = [normalize_link(link) for link in links]

            new_links = [link for link in normalized_links if link not in seen_links]

            logger.info(f"[{site}] –ü–æ –∫–ª—é—á—É '{keyword}': –≤—Å–µ–≥–æ —Å—Å—ã–ª–æ–∫: {len(links)}")
            logger.info(f"[{site}] –£–∂–µ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–æ: {len(seen_links)}")
            logger.info(f"[{site}] –ù–æ–≤—ã—Ö —Å—Å—ã–ª–æ–∫: {len(new_links)}")

            if new_links:
                await send_links_separately(new_links, site, keyword)
                logger.info(f"‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ {len(new_links)} –Ω–æ–≤—ã—Ö —Å—Å—ã–ª–æ–∫ –ø–æ –∫–ª—é—á—É '{keyword}' ({site})")
                seen_links.update(new_links)
                save_seen_links(SEEN_LINKS_FILE[site], seen_links)

            # –û–±–Ω–æ–≤–ª—è–µ–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ
            seen_links_store[site] = seen_links

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–ª—é—á–∞ '{keyword}' –Ω–∞ {site}: {e}")


async def run_for_site(site, search_func):
    logger.info(f"‚ñ∂Ô∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∞–π—Ç–∞ {site.upper()}")

    seen_links = load_seen_links(SEEN_LINKS_FILE[site])
    seen_links_store[site] = seen_links

    keywords = load_keywords(KEYWORDS_FILE)
    sema = SEMAPHORES[site]

    batch_size = 30
    for i in range(0, len(keywords), batch_size):
        batch = keywords[i:i + batch_size]
        logger.info(f"[{site}] üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ {i // batch_size + 1}/{(len(keywords)-1)//batch_size+1}")

        tasks = [
            asyncio.create_task(process_keyword(site, kw, search_func, sema))
            for kw in batch
        ]
        await asyncio.gather(*tasks)
        await asyncio.sleep(3)  # ‚è∏Ô∏è –ü–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏

    logger.info(f"[{site}] ‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ {len(keywords)} –∫–ª—é—á–µ–π")


async def start_parsers():
    logger.info("üöÄ –°—Ç–∞—Ä—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø–æ –≤—Å–µ–º —Å–∞–π—Ç–∞–º")

    await asyncio.gather(*[
        run_for_site(site, func) for site, func in PARSERS.items()
    ])

    logger.info("üìä –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à—ë–Ω –ø–æ –≤—Å–µ–º —Å–∞–π—Ç–∞–º.")


async def start_parsers_loop():
    while True:
        await start_parsers()
        logger.info("‚è∞ –û–∂–∏–¥–∞–Ω–∏–µ 60 —Å–µ–∫ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º —Ü–∏–∫–ª–æ–º...")
        await asyncio.sleep(60)


async def main():
    await asyncio.gather(
        start_parsers_loop(),
        run_bot(),
    )


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except (KeyboardInterrupt, SystemExit):
        logger.info("üõë –ü—Ä–æ–≥—Ä–∞–º–º–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –≤—Ä—É—á–Ω—É—é")
